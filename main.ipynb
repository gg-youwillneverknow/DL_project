{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>Age</th>\n",
       "      <th>VIP</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>Name</th>\n",
       "      <th>Transported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0001_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>B/0/P</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>39.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Maham Ofracculy</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>24.0</td>\n",
       "      <td>False</td>\n",
       "      <td>109.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>549.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>Juanna Vines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0003_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>58.0</td>\n",
       "      <td>True</td>\n",
       "      <td>43.0</td>\n",
       "      <td>3576.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6715.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>Altark Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0003_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/0/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>33.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1283.0</td>\n",
       "      <td>371.0</td>\n",
       "      <td>3329.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>Solam Susent</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0004_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>F/1/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>16.0</td>\n",
       "      <td>False</td>\n",
       "      <td>303.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>151.0</td>\n",
       "      <td>565.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Willy Santantines</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8688</th>\n",
       "      <td>9276_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>A/98/P</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>41.0</td>\n",
       "      <td>True</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6819.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1643.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>Gravior Noxnuther</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8689</th>\n",
       "      <td>9278_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>True</td>\n",
       "      <td>G/1499/S</td>\n",
       "      <td>PSO J318.5-22</td>\n",
       "      <td>18.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Kurta Mondalley</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8690</th>\n",
       "      <td>9279_01</td>\n",
       "      <td>Earth</td>\n",
       "      <td>False</td>\n",
       "      <td>G/1500/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>26.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1872.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Fayey Connon</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8691</th>\n",
       "      <td>9280_01</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>55 Cancri e</td>\n",
       "      <td>32.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353.0</td>\n",
       "      <td>3235.0</td>\n",
       "      <td>Celeon Hontichre</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8692</th>\n",
       "      <td>9280_02</td>\n",
       "      <td>Europa</td>\n",
       "      <td>False</td>\n",
       "      <td>E/608/S</td>\n",
       "      <td>TRAPPIST-1e</td>\n",
       "      <td>44.0</td>\n",
       "      <td>False</td>\n",
       "      <td>126.0</td>\n",
       "      <td>4688.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>Propsh Hontichre</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6606 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId HomePlanet CryoSleep     Cabin    Destination   Age    VIP  \\\n",
       "0        0001_01     Europa     False     B/0/P    TRAPPIST-1e  39.0  False   \n",
       "1        0002_01      Earth     False     F/0/S    TRAPPIST-1e  24.0  False   \n",
       "2        0003_01     Europa     False     A/0/S    TRAPPIST-1e  58.0   True   \n",
       "3        0003_02     Europa     False     A/0/S    TRAPPIST-1e  33.0  False   \n",
       "4        0004_01      Earth     False     F/1/S    TRAPPIST-1e  16.0  False   \n",
       "...          ...        ...       ...       ...            ...   ...    ...   \n",
       "8688     9276_01     Europa     False    A/98/P    55 Cancri e  41.0   True   \n",
       "8689     9278_01      Earth      True  G/1499/S  PSO J318.5-22  18.0  False   \n",
       "8690     9279_01      Earth     False  G/1500/S    TRAPPIST-1e  26.0  False   \n",
       "8691     9280_01     Europa     False   E/608/S    55 Cancri e  32.0  False   \n",
       "8692     9280_02     Europa     False   E/608/S    TRAPPIST-1e  44.0  False   \n",
       "\n",
       "      RoomService  FoodCourt  ShoppingMall     Spa  VRDeck               Name  \\\n",
       "0             0.0        0.0           0.0     0.0     0.0    Maham Ofracculy   \n",
       "1           109.0        9.0          25.0   549.0    44.0       Juanna Vines   \n",
       "2            43.0     3576.0           0.0  6715.0    49.0      Altark Susent   \n",
       "3             0.0     1283.0         371.0  3329.0   193.0       Solam Susent   \n",
       "4           303.0       70.0         151.0   565.0     2.0  Willy Santantines   \n",
       "...           ...        ...           ...     ...     ...                ...   \n",
       "8688          0.0     6819.0           0.0  1643.0    74.0  Gravior Noxnuther   \n",
       "8689          0.0        0.0           0.0     0.0     0.0    Kurta Mondalley   \n",
       "8690          0.0        0.0        1872.0     1.0     0.0       Fayey Connon   \n",
       "8691          0.0     1049.0           0.0   353.0  3235.0   Celeon Hontichre   \n",
       "8692        126.0     4688.0           0.0     0.0    12.0   Propsh Hontichre   \n",
       "\n",
       "      Transported  \n",
       "0           False  \n",
       "1            True  \n",
       "2           False  \n",
       "3           False  \n",
       "4            True  \n",
       "...           ...  \n",
       "8688        False  \n",
       "8689        False  \n",
       "8690         True  \n",
       "8691        False  \n",
       "8692         True  \n",
       "\n",
       "[6606 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#import dataset\n",
    "df = pd.read_csv('spaceship-titanic/train.csv').dropna(axis=0,how='any')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#specify target label\n",
    "target = 'Transported'\n",
    "\n",
    "data = [name for name in df.columns if name != target]\n",
    "numeric_data = []\n",
    "string_data = []\n",
    "tokenizers = {}\n",
    "\n",
    "#organize data based on data types\n",
    "dtypes = dict(df[data].dtypes)\n",
    "\n",
    "for name in data:\n",
    "    if str(dtypes[name]) == 'object':\n",
    "        string_data.append(name)\n",
    "        \n",
    "        #create tokenizer\n",
    "        value_set = sorted(list(set([x if type(x) == str or type(x) == bool else '' for x in df[name]])))\n",
    "        tokenizer = {token:num for num,token in enumerate(value_set)}\n",
    "        tokenizers[name] = tokenizer\n",
    "\n",
    "    else:\n",
    "        numeric_data.append(name)\n",
    "\n",
    "#token count for each string feature\n",
    "n_tokens = {name:len(tokenizer) for name,tokenizer in tokenizers.items()}\n",
    "#determine network embedding size\n",
    "n_embeddings = {name:int(np.ceil(np.log(n_token))) for name,n_token in n_tokens.items()}\n",
    "#create scalers for each numeric feature\n",
    "scalers = {name:MinMaxScaler(feature_range=(-1.,1.),copy=True) for name in numeric_data}\n",
    "\n",
    "#scale numeric features\n",
    "scaled_numeric_data = {name:scalers[name].fit_transform(df[name].to_numpy().copy().reshape(-1,1)).reshape(-1) for name in numeric_data}\n",
    "scaled_numeric_df = pd.DataFrame(scaled_numeric_data)\n",
    "\n",
    "#tokenize string features\n",
    "tokenized_string_data = {name:np.vectorize(tokenizers[name].get)(df[name].to_numpy().copy()) for name in string_data}\n",
    "tokenized_string_df = pd.DataFrame(tokenized_string_data)\n",
    "\n",
    "processed_df = scaled_numeric_df.join(tokenized_string_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>RoomService</th>\n",
       "      <th>FoodCourt</th>\n",
       "      <th>ShoppingMall</th>\n",
       "      <th>Spa</th>\n",
       "      <th>VRDeck</th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>HomePlanet</th>\n",
       "      <th>CryoSleep</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Destination</th>\n",
       "      <th>VIP</th>\n",
       "      <th>Name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.012658</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>137</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.392405</td>\n",
       "      <td>-0.978024</td>\n",
       "      <td>-0.999396</td>\n",
       "      <td>-0.995919</td>\n",
       "      <td>-0.951000</td>\n",
       "      <td>-0.995673</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1823</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.468354</td>\n",
       "      <td>-0.991331</td>\n",
       "      <td>-0.760105</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.400660</td>\n",
       "      <td>-0.995181</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.164557</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.913930</td>\n",
       "      <td>-0.939443</td>\n",
       "      <td>-0.702874</td>\n",
       "      <td>-0.981019</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.594937</td>\n",
       "      <td>-0.938911</td>\n",
       "      <td>-0.995304</td>\n",
       "      <td>-0.975353</td>\n",
       "      <td>-0.949572</td>\n",
       "      <td>-0.999803</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1825</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6601</th>\n",
       "      <td>0.037975</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.542549</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.853356</td>\n",
       "      <td>-0.992722</td>\n",
       "      <td>6601</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6602</th>\n",
       "      <td>-0.544304</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6602</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4293</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3707</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6603</th>\n",
       "      <td>-0.341772</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.694442</td>\n",
       "      <td>-0.999911</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>6603</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4298</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6604</th>\n",
       "      <td>-0.189873</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.929628</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.968493</td>\n",
       "      <td>-0.681845</td>\n",
       "      <td>6604</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1778</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6605</th>\n",
       "      <td>0.113924</td>\n",
       "      <td>-0.974597</td>\n",
       "      <td>-0.685506</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>-0.998820</td>\n",
       "      <td>6605</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1778</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4948</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6606 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Age  RoomService  FoodCourt  ShoppingMall       Spa    VRDeck  \\\n",
       "0    -0.012658    -1.000000  -1.000000     -1.000000 -1.000000 -1.000000   \n",
       "1    -0.392405    -0.978024  -0.999396     -0.995919 -0.951000 -0.995673   \n",
       "2     0.468354    -0.991331  -0.760105     -1.000000 -0.400660 -0.995181   \n",
       "3    -0.164557    -1.000000  -0.913930     -0.939443 -0.702874 -0.981019   \n",
       "4    -0.594937    -0.938911  -0.995304     -0.975353 -0.949572 -0.999803   \n",
       "...        ...          ...        ...           ...       ...       ...   \n",
       "6601  0.037975    -1.000000  -0.542549     -1.000000 -0.853356 -0.992722   \n",
       "6602 -0.544304    -1.000000  -1.000000     -1.000000 -1.000000 -1.000000   \n",
       "6603 -0.341772    -1.000000  -1.000000     -0.694442 -0.999911 -1.000000   \n",
       "6604 -0.189873    -1.000000  -0.929628     -1.000000 -0.968493 -0.681845   \n",
       "6605  0.113924    -0.974597  -0.685506     -1.000000 -1.000000 -0.998820   \n",
       "\n",
       "      PassengerId  HomePlanet  CryoSleep  Cabin  Destination  VIP  Name  \n",
       "0               0           1          0    137            2    0  4080  \n",
       "1               1           0          0   1823            2    0  3491  \n",
       "2               2           1          0      1            2    1   353  \n",
       "3               3           1          0      1            2    0  5536  \n",
       "4               4           0          0   1825            2    0  6464  \n",
       "...           ...         ...        ...    ...          ...  ...   ...  \n",
       "6601         6601           1          0    134            0    1  2723  \n",
       "6602         6602           0          1   4293            1    0  3707  \n",
       "6603         6603           0          0   4298            2    0  2314  \n",
       "6604         6604           1          0   1778            0    0  1244  \n",
       "6605         6605           1          0   1778            2    0  4948  \n",
       "\n",
       "[6606 rows x 13 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split data for training and testing\n",
    "data_split_mask = np.random.rand(len(df)) < 0.8\n",
    "\n",
    "train_df = processed_df[data_split_mask].reset_index(drop=True)\n",
    "train_target_df = df[[target]][data_split_mask].reset_index(drop=True)\n",
    "\n",
    "test_df = processed_df[~data_split_mask].reset_index(drop=True)\n",
    "test_target_df = df[[target]][~data_split_mask].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "from skopt.plots import plot_objective, plot_histogram\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(processed_df, df[target], random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search over different model types\n",
    "\n",
    "C = [1000, 2000]\n",
    "gamm = [1, 0.1, 0.01, 0.001, 0.0001]\n",
    "kernel = ['poly', 'rbf'] #['linear',\n",
    "\n",
    "SVC_grid = {\n",
    "    'svc__C': C,\n",
    "    #'svc__gamma': gamm,\n",
    "    'svc__kernel': kernel,\n",
    "}\n",
    "\n",
    "# Number of trees in random forest\n",
    "n_estimators = [10, 50, 100] #[int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [5, 10] # [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "RF_grid = {\n",
    "    'rf__n_estimators': n_estimators,\n",
    "    'rf__max_features': max_features,\n",
    "    'rf__max_depth': max_depth,\n",
    "    'rf__min_samples_split': min_samples_split,\n",
    "    'rf__min_samples_leaf': min_samples_leaf,\n",
    "    'rf__bootstrap': bootstrap\n",
    "}\n",
    "\n",
    "#C = np.logspace(-8, 8, 50)\n",
    "C = [1000, 10000, 100000, 150000, 300000]\n",
    "\n",
    "penalty = ['l2'] # l1 doesn't exist\n",
    "\n",
    "LR_grid = {\n",
    "    'lr__C': C,\n",
    "    'lr__penalty': penalty,\n",
    "}\n",
    "\n",
    "k_range = list(range(20, 75))\n",
    "weights = ['uniform','distance']\n",
    "metric = ['euclidean','manhattan']\n",
    "\n",
    "KNN_grid = {\n",
    "    'knn__n_neighbors': k_range, # I assume you meant \"n_neighbors\" for \"k\"\n",
    "    'knn__weights': weights,\n",
    "    'knn__metric': metric,\n",
    "}\n",
    "\n",
    "params = [SVC_grid, RF_grid, LR_grid, KNN_grid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.6201759518068656\n",
      "test score: 0.6302226013593238\n",
      "best params: {'svc__C': 2000, 'svc__kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "pipe_1 = Pipeline(steps=[('svc', SVC(random_state=0))])\n",
    "opt = GridSearchCV(\n",
    "    pipe_1, params[0], cv=3, n_jobs=-1, scoring='roc_auc'\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(X_test, y_test))\n",
    "print(\"best params: %s\" % str(opt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Nicholas\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_forest.py:427: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features='sqrt'` or remove this parameter as it is also the default value for RandomForestClassifiers and ExtraTreesClassifiers.\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.8861532177693586\n",
      "test score: 0.8728180684234981\n",
      "best params: {'rf__bootstrap': False, 'rf__max_depth': 10, 'rf__max_features': 'auto', 'rf__min_samples_leaf': 2, 'rf__min_samples_split': 5, 'rf__n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "pipe_2 = Pipeline(steps=[('rf', RandomForestClassifier(random_state=0))])\n",
    "opt = GridSearchCV(\n",
    "    pipe_2, params[1], cv=3, n_jobs=-1, scoring='roc_auc'\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(X_test, y_test))\n",
    "print(\"best params: %s\" % str(opt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.7930711970607992\n",
      "test score: 0.7605778518463147\n",
      "best params: {'lr__C': 150000, 'lr__penalty': 'l2'}\n"
     ]
    }
   ],
   "source": [
    "pipe_3 = Pipeline(steps=[('lr', LogisticRegression(random_state=0))])\n",
    "opt = GridSearchCV(\n",
    "    pipe_3, params[2], cv=3, n_jobs=-1, scoring='roc_auc'\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(X_test, y_test))\n",
    "print(\"best params: %s\" % str(opt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val. score: 0.6054600214736116\n",
      "test score: 0.6211071878238361\n",
      "best params: {'knn__metric': 'manhattan', 'knn__n_neighbors': 58, 'knn__weights': 'uniform'}\n"
     ]
    }
   ],
   "source": [
    "pipe_4 = Pipeline(steps=[('knn', KNeighborsClassifier())])\n",
    "opt = GridSearchCV(\n",
    "    pipe_4, params[3], cv=3, n_jobs=-1, scoring='roc_auc'\n",
    ")\n",
    "\n",
    "opt.fit(X_train, y_train)\n",
    "\n",
    "print(\"val. score: %s\" % opt.best_score_)\n",
    "print(\"test score: %s\" % opt.score(X_test, y_test))\n",
    "print(\"best params: %s\" % str(opt.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,Dense,BatchNormalization,Concatenate,GaussianNoise\n",
    "from tensorflow.keras.optimizers import Nadam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define latent dimension size\n",
    "latent_dim = int(np.ceil(np.log(len(X_train)*len(processed_df))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input for random seed vecotors\n",
    "latent_inputs = Input(shape=(latent_dim,),name='latent')\n",
    "#input for target specification\n",
    "target_inputs = Input(shape=(2,),name='target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {'latent':latent_inputs,'target':target_inputs}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Concatenate()([latent_inputs,target_inputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    net = Dense(32+len(processed_df), activation='relu',\n",
    "                kernel_initializer='he_uniform')(net)\n",
    "    net = BatchNormalization()(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs = {}\n",
    "#numeric data outputs\n",
    "for name in numeric_data:\n",
    "    outputs[name] = Dense(1,activation='tanh',\n",
    "                            kernel_initializer='glorot_uniform',name=name)(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_nets = Dense(len(string_data),activation='relu',\n",
    "                        kernel_initializer='he_uniform')(net)\n",
    "string_nets = BatchNormalization()(string_nets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string data outputs\n",
    "for name,n_token in n_tokens.items():\n",
    "    string_net = Dense(n_embeddings[name],activation='relu',\n",
    "                        kernel_initializer='he_uniform')(string_nets)\n",
    "    string_net = BatchNormalization()(string_net)\n",
    "    outputs[name] = Dense(n_token,activation='softmax',\n",
    "                            kernel_initializer='glorot_uniform',name=name)(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = Model(inputs=inputs, outputs=outputs)\n",
    "generator.compile(loss='categorical_crossentropy',\n",
    "                      optimizer=Nadam(clipnorm=1.))\n",
    "\n",
    "generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {}\n",
    "numeric_nets = []\n",
    "string_nets = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#numerica data inputs\n",
    "for name in numeric_data:\n",
    "    numeric_input = Input(shape=(1,),name=name)\n",
    "    inputs[name] = numeric_input\n",
    "    \n",
    "    numeric_net = GaussianNoise(0.01)(numeric_input)\n",
    "    numeric_nets.append(numeric_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#string data inputs\n",
    "for name,n_token in n_tokens.items():\n",
    "    string_input = Input(shape=(n_token,),name=name)\n",
    "    inputs[name] = string_input\n",
    "\n",
    "    string_net = GaussianNoise(0.05)(string_input)\n",
    "    string_net = Dense(n_embeddings[name],activation='relu',\n",
    "                        kernel_initializer='he_uniform')(string_net)\n",
    "    string_nets.append(string_net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "string_nets = Concatenate()(string_nets)\n",
    "string_nets = BatchNormalization()(string_nets)\n",
    "string_nets = [Dense(len(string_data),activation='relu',\n",
    "                        kernel_initializer='he_uniform')(string_nets)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Concatenate()(numeric_nets + string_nets)\n",
    "net = BatchNormalization()(net)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in range(2):\n",
    "    net = Dense(64+len(data), activation='relu',\n",
    "                kernel_initializer='he_uniform')(net)\n",
    "    net = BatchNormalization()(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#discrimination/classification\n",
    "outputs = Dense(3, activation='softmax',\n",
    "                kernel_initializer='glorot_uniform')(net)\n",
    "\n",
    "discriminator = Model(inputs=inputs, outputs=outputs)\n",
    "discriminator.compile(loss='categorical_crossentropy',\n",
    "                        optimizer=Nadam(clipnorm=1.))\n",
    "\n",
    "discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#disable discriminator training\n",
    "discriminator.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#input for random seed vecotors\n",
    "latent_inputs = Input(shape=(latent_dim,),name='latent')\n",
    "#input for target specification\n",
    "target_inputs = Input(shape=(2,),name='target')\n",
    "\n",
    "inputs = {'latent':latent_inputs,'target':target_inputs}\n",
    "\n",
    "net = generator([latent_inputs, target_inputs])\n",
    "outputs = discriminator(net)\n",
    "\n",
    "gan = Model(inputs=inputs, outputs=outputs)\n",
    "gan.compile(loss='categorical_crossentropy', optimizer=Nadam(clipnorm=1.))\n",
    "gan"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a305b1848269da482af96078ef76f7dd93b3ac670f4fbba16318af4948b4cd0a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
